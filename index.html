<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Understanding Strings and Tokenization</title>

    <!-- Load React -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/react/18.2.0/umd/react.production.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/react-dom/18.2.0/umd/react-dom.production.min.js"></script>

    <!-- Load Babel for JSX -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/babel-standalone/7.23.5/babel.min.js"></script>

    <!-- Load Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>

    <script>
      // Add dark mode configuration to Tailwind
      tailwind.config = {
        darkMode: "class",
        theme: {
          extend: {
            typography: {
              invert: {
                css: {
                  "--tw-prose-body": "rgb(229, 231, 235)",
                  "--tw-prose-headings": "rgb(255, 255, 255)",
                  "--tw-prose-links": "rgb(96, 165, 250)",
                  "--tw-prose-bold": "rgb(255, 255, 255)",
                  "--tw-prose-counters": "rgb(229, 231, 235)",
                  "--tw-prose-bullets": "rgb(229, 231, 235)",
                  "--tw-prose-hr": "rgb(75, 85, 99)",
                  "--tw-prose-quotes": "rgb(229, 231, 235)",
                  "--tw-prose-quote-borders": "rgb(75, 85, 99)",
                  "--tw-prose-captions": "rgb(156, 163, 175)",
                  "--tw-prose-code": "rgb(255, 255, 255)",
                  "--tw-prose-pre-code": "rgb(229, 231, 235)",
                  "--tw-prose-pre-bg": "rgb(55, 65, 81)",
                },
              },
            },
          },
        },
      };
    </script>

    <style>
      /* Dark mode transitions */
      .dark-transition {
        transition: background-color 0.3s ease, color 0.3s ease;
      }

      /* Dark mode text colors */
      .dark .text-gray-500 {
        color: rgb(209, 213, 219);
      }

      .dark .text-gray-600 {
        color: rgb(229, 231, 235);
      }

      .dark label,
      .dark .font-medium {
        color: rgb(229, 231, 235);
      }

      .dark textarea,
      .dark select {
        color: rgb(229, 231, 235);
      }

      .dark .bg-blue-50 {
        background-color: rgb(30, 58, 138);
        color: rgb(229, 231, 235);
      }

      /* Educational content dark mode styles */
      .dark .prose {
        color: rgb(229, 231, 235);
      }

      .dark .prose strong {
        color: rgb(255, 255, 255);
      }

      .dark .prose h1,
      .dark .prose h2,
      .dark .prose h3 {
        color: rgb(255, 255, 255);
      }

      .dark .prose ul > li::before {
        background-color: rgb(209, 213, 219);
      }

      .dark .prose a {
        color: rgb(96, 165, 250);
      }

      .dark .prose blockquote {
        color: rgb(229, 231, 235);
        border-left-color: rgb(75, 85, 99);
      }

      .dark .prose code {
        color: rgb(255, 255, 255);
        background-color: rgb(55, 65, 81);
      }

      .dark .prose em {
        color: rgb(229, 231, 235);
      }
    </style>
  </head>
  <body class="bg-gray-100 dark:bg-gray-900 min-h-screen dark-transition">
    <!-- Dark Mode Toggle -->
    <div class="fixed top-4 right-4 z-50">
      <button
        onclick="document.documentElement.classList.toggle('dark')"
        class="bg-gray-200 dark:bg-gray-700 p-2 rounded-lg shadow-lg hover:bg-gray-300 dark:hover:bg-gray-600 dark-transition"
        aria-label="Toggle dark mode"
      >
        <svg
          class="w-6 h-6 hidden dark:block text-yellow-300"
          fill="currentColor"
          viewBox="0 0 20 20"
        >
          <!-- Sun icon -->
          <path
            d="M10 2a1 1 0 011 1v1a1 1 0 11-2 0V3a1 1 0 011-1zm4 8a4 4 0 11-8 0 4 4 0 018 0zm-.464 4.95l.707.707a1 1 0 001.414-1.414l-.707-.707a1 1 0 00-1.414 1.414zm2.12-10.607a1 1 0 010 1.414l-.706.707a1 1 0 11-1.414-1.414l.707-.707a1 1 0 011.414 0zM17 11a1 1 0 100-2h-1a1 1 0 100 2h1zm-7 4a1 1 0 011 1v1a1 1 0 11-2 0v-1a1 1 0 011-1zM5.05 6.464A1 1 0 106.465 5.05l-.708-.707a1 1 0 00-1.414 1.414l.707.707zm1.414 8.486l-.707.707a1 1 0 01-1.414-1.414l.707-.707a1 1 0 011.414 1.414zM4 11a1 1 0 100-2H3a1 1 0 000 2h1z"
          />
        </svg>
        <svg
          class="w-6 h-6 block dark:hidden text-gray-800"
          fill="currentColor"
          viewBox="0 0 20 20"
        >
          <!-- Moon icon -->
          <path
            d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"
          />
        </svg>
      </button>
    </div>

    <!-- Educational Content Section -->
    <div class="max-w-4xl mx-auto pt-8 px-6">
      <div
        class="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6 mb-8 dark-transition"
      >
        <div class="prose dark:prose-invert max-w-none">
          <h1 class="text-3xl font-bold mb-6">
            Understanding Python Strings and Tokenization
          </h1>

          <p class="mb-4">
            Strings are fundamental to programming in Python, playing a crucial
            role in various aspects of software development and artificial
            intelligence. Understanding strings is essential for several
            reasons:
          </p>

          <h2 class="text-2xl font-bold mt-6 mb-4">
            Data Representation and Manipulation
          </h2>
          <p class="mb-4">
            Strings in Python are used to represent and manipulate textual data.
            They can contain letters, numbers, symbols, and whitespace, making
            them versatile for handling various types of information. This
            capability is vital for:
          </p>
          <ul class="list-disc pl-6 mb-4">
            <li class="mb-2">
              <strong>Text Processing</strong>: Strings allow you to work with
              human-readable text, enabling tasks like parsing, formatting, and
              analyzing textual content.
            </li>
            <li class="mb-2">
              <strong>Data Input/Output</strong>: They facilitate the exchange
              of information between users and programs, as well as between
              different parts of a program.
            </li>
          </ul>

          <h2 class="text-2xl font-bold mt-6 mb-4">
            Strings in Artificial Intelligence
          </h2>
          <p class="mb-4">
            String manipulation plays a crucial role in modern AI applications
            and natural language processing:
          </p>
          <ul class="list-disc pl-6 mb-4">
            <li class="mb-4">
              <strong>Text Preprocessing</strong>: AI models require carefully
              formatted text input. String operations are essential for:
              <ul class="list-circle pl-6 mt-2">
                <li>
                  <strong>Tokenization</strong> - breaking text into smaller
                  units
                </li>
                <li>
                  <strong>Normalization</strong> - standardizing text format and
                  case
                </li>
                <li>
                  <strong>Cleaning</strong> - removing unwanted characters or
                  formatting
                </li>
              </ul>
            </li>
            <li class="mb-4">
              <strong>Prompt Engineering</strong>: When working with large
              language models, string formatting is crucial for:
              <ul class="list-circle pl-6 mt-2">
                <li>Constructing effective prompts</li>
                <li>Formatting system instructions</li>
                <li>Processing and validating model responses</li>
              </ul>
            </li>
          </ul>

          <p class="mb-4">
            The rise of AI and
            <strong>natural language processing (NLP)</strong> has made string
            manipulation more important than ever, as it forms the foundation
            for how we prepare, process, and handle text data for AI
            applications.
          </p>

          <p class="mb-4">
            <strong
              ><em
                >Natural Language Processing (NLP) is a branch of artificial
                intelligence that helps computers understand, interpret, and
                generate human language in a useful way</em
              ></strong
            >. It's what allows computers to read text, hear speech, understand
            it, measure sentiment, and determine which parts are important.
          </p>

          <p class="mb-6">
            Think of it as the technology that bridges the gap between how
            humans communicate naturally and how computers process information.
            Just like how we can understand this sentence in English, NLP helps
            computers make sense of human languages.
          </p>

          <h2 class="text-2xl font-bold mt-6 mb-4">
            Understanding Tokenization
          </h2>
          <p class="mb-4">
            <strong
              >Tokenization is the process of breaking down text into smaller
              pieces called tokens.</strong
            >
            Think of it like breaking a sentence into bite-sized chunks that an
            AI model can understand. These chunks aren't always just individual
            words - they can be parts of words, punctuation marks, or even
            common phrases.
          </p>

          <h3 class="text-xl font-bold mt-4 mb-2">
            Common Tokenization Methods:
          </h3>
          <ul class="list-disc pl-6 mb-4">
            <li class="mb-2">
              <strong>Word-level Tokenization</strong>: Splits text into
              individual words based on spaces and punctuation.
            </li>
            <li class="mb-2">
              <strong>Character-level Tokenization</strong>: Breaks text down
              into individual characters.
            </li>
            <li class="mb-2">
              <strong>Subword Tokenization</strong>: The most common method in
              modern LLMs, breaking words into meaningful subunits.
            </li>
          </ul>

          <div class="bg-blue-50 p-4 rounded-md mb-6">
            <p class="font-semibold mb-2">Try It Out!</p>
            <p>
              Use the interactive Token Visualizer below to experiment with
              different tokenization methods and see how they work in practice.
            </p>
          </div>
        </div>
      </div>
    </div>

    <!-- Token Visualizer App -->
    <div id="root"></div>

    <!-- Conclusion Section -->
    <div class="max-w-4xl mx-auto px-6 pb-8">
      <div
        class="bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6 mt-8 dark-transition"
      >
        <div class="prose dark:prose-invert max-w-none">
          <p class="mb-6">
            Each of these methods has its own trade-offs in terms of vocabulary
            size, ability to handle unknown words, and computational efficiency.
            The choice of tokenization method can significantly impact an LLM's
            performance, especially in tasks involving multiple languages or
            specialized domains.
          </p>

          <h2 class="text-2xl font-bold mt-6 mb-4">Conclusion</h2>
          <p class="mb-4">
            Mastering strings in Python is crucial for effective programming.
            They are not just for storing text; strings are integral to data
            processing, user interaction, file handling, and interfacing with
            external systems. Tokenization is often called a "preprocessing"
            step in NLP - it's the crucial first stage that enables all other
            language processing tasks. Formatting, manipulating, and
            transforming text is an important for of AI. Learning how to master
            text and string manipulation with Python will make you a powerful AI
            developer.
          </p>
        </div>
      </div>
    </div>

    <script type="text/babel">
      const TokenVisualizer = () => {
        const [text, setText] = React.useState(
          "Tokenization is the process of breaking down text into smaller pieces called tokens."
        );
        const [method, setMethod] = React.useState("subword");

        // Basic vocabulary for subword tokenization demonstration
        const vocabulary = {
          prefixes: [
            "un",
            "re",
            "pre",
            "post",
            "anti",
            "sub",
            "super",
            "inter",
          ],
          suffixes: [
            "ing",
            "ed",
            "er",
            "est",
            "ly",
            "tion",
            "able",
            "ment",
            "ness",
          ],
          commonWords: [
            "the",
            "is",
            "are",
            "was",
            "to",
            "and",
            "in",
            "on",
            "at",
            "for",
          ],
          roots: [
            "learn",
            "develop",
            "token",
            "model",
            "compute",
            "process",
            "system",
          ],
        };

        const tokenizationMethods = {
          words: {
            name: "Word-based",
            tokenize: (text) => {
              return text.match(/\b\w+\b|\s+|[^\w\s]/g) || [];
            },
          },
          subword: {
            name: "Subword-based",
            tokenize: (text) => {
              let tokens = [];
              const words = text.match(/\b\w+\b|\s+|[^\w\s]/g) || [];

              words.forEach((word) => {
                if (/^\s+$/.test(word) || /^[^\w\s]$/.test(word)) {
                  tokens.push(word);
                  return;
                }

                let processed = false;
                const lowerWord = word.toLowerCase();

                if (vocabulary.commonWords.includes(lowerWord)) {
                  tokens.push(word);
                  return;
                }

                for (const prefix of vocabulary.prefixes) {
                  if (
                    lowerWord.startsWith(prefix) &&
                    lowerWord.length > prefix.length
                  ) {
                    const remainder = word.slice(prefix.length);
                    tokens.push(word.slice(0, prefix.length), remainder);
                    processed = true;
                    break;
                  }
                }

                if (!processed) {
                  for (const suffix of vocabulary.suffixes) {
                    if (
                      lowerWord.endsWith(suffix) &&
                      lowerWord.length > suffix.length
                    ) {
                      const root = word.slice(0, -suffix.length);
                      if (vocabulary.roots.includes(root.toLowerCase())) {
                        tokens.push(root, word.slice(-suffix.length));
                        processed = true;
                        break;
                      }
                    }
                  }
                }

                if (!processed) {
                  tokens.push(word);
                }
              });

              return tokens;
            },
          },
          characters: {
            name: "Character-based",
            tokenize: (text) => text.split(""),
          },
        };

        const colors = [
          "bg-blue-200",
          "bg-green-200",
          "bg-purple-200",
          "bg-yellow-200",
          "bg-red-200",
          "bg-indigo-200",
          "bg-pink-200",
          "bg-orange-200",
        ];

        const getTokens = React.useCallback((text, method) => {
          if (!text.trim()) return [];

          const tokenizer = tokenizationMethods[method].tokenize;
          return tokenizer(text).map((token, index) => ({
            id: index + 1,
            text: token,
            color: colors[index % colors.length],
            isSubword:
              method === "subword" &&
              !(/^\s+$/.test(token) || /^[^\w\s]$/.test(token)) &&
              token.length < text.length,
          }));
        }, []);

        const tokens = getTokens(text, method);

        const TokenDisplay = ({ tokens }) => (
          <div className="font-mono text-sm leading-relaxed break-words">
            {tokens.map((token) => (
              <span
                key={token.id}
                className={`inline-block ${token.color} px-1 py-0.5 m-0.5 rounded group relative`}
              >
                {token.text === " " ? "␣" : token.text}
                {token.isSubword && (
                  <span className="invisible group-hover:visible absolute -top-6 left-0 bg-gray-800 text-white px-2 py-1 rounded text-xs">
                    Subword
                  </span>
                )}
              </span>
            ))}
          </div>
        );

        return (
          <div className="max-w-4xl mx-auto bg-white dark:bg-gray-800 rounded-lg shadow-lg p-6 dark-transition">
            <h1 className="text-2xl font-bold mb-6 dark:text-white">
              Token Visualizer
            </h1>

            <div className="space-y-4">
              <div className="space-y-2">
                <label className="block text-sm font-medium">
                  Tokenization Method:
                </label>
                <select
                  value={method}
                  onChange={(e) => setMethod(e.target.value)}
                  className="w-full p-2 border rounded-md bg-white dark:bg-gray-700"
                >
                  {Object.entries(tokenizationMethods).map(
                    ([key, { name }]) => (
                      <option key={key} value={key}>
                        {name}
                      </option>
                    )
                  )}
                </select>
              </div>

              <div className="space-y-2">
                <label className="block text-sm font-medium">
                  Enter text to tokenize:
                </label>
                <textarea
                  value={text}
                  onChange={(e) => setText(e.target.value)}
                  className="w-full h-32 p-2 border rounded-md font-mono bg-white dark:bg-gray-700"
                  placeholder="Type or paste text here..."
                />
              </div>

              <div className="space-y-2">
                <div className="flex justify-between items-center">
                  <label className="block text-sm font-medium">
                    Tokenized Display:
                  </label>
                  <span className="text-sm text-gray-500">
                    Total tokens: {tokens.length}
                  </span>
                </div>

                <div className="border rounded-md p-4 bg-gray-50 dark:bg-gray-700 min-h-32 overflow-auto">
                  <TokenDisplay tokens={tokens} />
                </div>
              </div>

              <div className="space-y-2">
                <label className="block text-sm font-medium">
                  Token Details:
                </label>
                <div className="border rounded-md p-4 bg-gray-50 dark:bg-gray-700 max-h-64 overflow-auto">
                  <div className="space-y-1">
                    {tokens.map((token) => (
                      <div
                        key={token.id}
                        className="flex items-center space-x-4 font-mono text-sm"
                      >
                        <span className="w-8 text-gray-500">{token.id}.</span>
                        <span className={`${token.color} px-2 py-0.5 rounded`}>
                          {token.text === " " ? "␣" : token.text}
                        </span>
                        {token.isSubword && (
                          <span className="text-xs text-gray-500">Subword</span>
                        )}
                      </div>
                    ))}
                  </div>
                </div>
              </div>

              {method === "subword" && (
                <div className="text-sm text-gray-600 space-y-2">
                  <p className="font-medium">About Subword Tokenization:</p>
                  <p>
                    This demonstrates a simplified version of subword
                    tokenization. It breaks down words into meaningful subunits
                    (prefixes, suffixes, and root words) when possible. Hover
                    over tokens to see which ones are subwords.
                  </p>
                  <p>
                    Real language models use more sophisticated algorithms like
                    BPE (Byte-Pair Encoding) or WordPiece, which learn subword
                    units from training data.
                  </p>
                </div>
              )}
            </div>
          </div>
        );
      };

      // Render the app
      const root = ReactDOM.createRoot(document.getElementById("root"));
      root.render(<TokenVisualizer />);
    </script>
  </body>
</html>
